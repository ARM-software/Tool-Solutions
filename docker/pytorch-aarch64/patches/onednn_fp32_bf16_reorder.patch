 *******************************************************************************
 Copyright 2023-2024 Arm Limited and affiliates.
 SPDX-License-Identifier: Apache-2.0

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 *******************************************************************************
diff --git a/include/oneapi/dnnl/dnnl.hpp b/include/oneapi/dnnl/dnnl.hpp
index 11b0ff663fd..5aca83bf07f 100644
--- a/include/oneapi/dnnl/dnnl.hpp
+++ b/include/oneapi/dnnl/dnnl.hpp
@@ -1188,6 +1188,8 @@ struct memory : public handle<dnnl_memory_t> {
         AB16b32a2b = dnnl_AB16b32a2b,
         AB16b48a2b = dnnl_AB16b48a2b,
         AB16b64a2b = dnnl_AB16b64a2b,
+        Ab4a = dnnl_Ab4a,
+        Ab8a = dnnl_Ab8a,
         Abc16a = dnnl_Abc16a,
         ABc16a16b = dnnl_ABc16a16b,
         ABc4a4b = dnnl_ABc4a4b,
@@ -2365,6 +2367,8 @@ struct memory : public handle<dnnl_memory_t> {
         aCB16c4b = dnnl_aCB16c4b,
         BA16b2a = dnnl_BA16b2a,
         BA16b4a = dnnl_BA16b4a,
+        BA4b4a = dnnl_BA4b4a,
+        BA8b4a = dnnl_BA8b4a,
         aBC16b16c = dnnl_aBC16b16c,
         aBC16b32c = dnnl_aBC16b32c,
         AB16a16b = dnnl_AB16a16b,
diff --git a/include/oneapi/dnnl/dnnl_types.h b/include/oneapi/dnnl/dnnl_types.h
index 4e3adff3e0d..0cc67ac856a 100644
--- a/include/oneapi/dnnl/dnnl_types.h
+++ b/include/oneapi/dnnl/dnnl_types.h
@@ -227,7 +227,8 @@ typedef enum {
     dnnl_abcdefghijlk, ///< permuted 12D tensor
 
     // Opaque blocked formats
-
+    dnnl_Ab4a,
+    dnnl_Ab8a,
     dnnl_Abc16a,
     dnnl_ABc16a16b,
     dnnl_ABc32a32b,
@@ -708,6 +709,8 @@ typedef enum {
     dnnl_aCB16c4b,
     dnnl_BA16b2a,
     dnnl_BA16b4a,
+    dnnl_BA4b4a,
+    dnnl_BA8b4a,
     dnnl_aBC16b16c,
     dnnl_aBC16b32c,
     dnnl_AB16a16b,
diff --git a/src/common/c_types_map.hpp b/src/common/c_types_map.hpp
index 2b31448eff5..ca6163c432a 100644
--- a/src/common/c_types_map.hpp
+++ b/src/common/c_types_map.hpp
@@ -328,6 +328,8 @@ const format_tag_t AB16b16a2b = dnnl_AB16b16a2b;
 const format_tag_t AB16b32a2b = dnnl_AB16b32a2b;
 const format_tag_t AB16b48a2b = dnnl_AB16b48a2b;
 const format_tag_t AB16b64a2b = dnnl_AB16b64a2b;
+const format_tag_t BA4b4a = dnnl_BA4b4a;
+const format_tag_t BA8b4a = dnnl_BA8b4a;
 const format_tag_t BA16a16b = dnnl_BA16a16b;
 const format_tag_t BA16a32b = dnnl_BA16a32b;
 const format_tag_t BA16a48b = dnnl_BA16a48b;
@@ -353,6 +355,8 @@ const format_tag_t aCB16b32c4b = dnnl_aCB16b32c4b;
 const format_tag_t aCB16b48c4b = dnnl_aCB16b48c4b;
 const format_tag_t aCB16b64c4b = dnnl_aCB16b64c4b;
 
+const format_tag_t Ab4a = dnnl_Ab4a;
+const format_tag_t Ab8a = dnnl_Ab8a;
 const format_tag_t Abc16a = dnnl_Abc16a;
 const format_tag_t ABc16a16b = dnnl_ABc16a16b;
 const format_tag_t ABc4a2b = dnnl_ABc4a2b;
diff --git a/src/common/dnnl_debug_autogenerated.cpp b/src/common/dnnl_debug_autogenerated.cpp
index c827e53e85d..b4c49be2868 100644
--- a/src/common/dnnl_debug_autogenerated.cpp
+++ b/src/common/dnnl_debug_autogenerated.cpp
@@ -1689,6 +1689,10 @@ const char *dnnl_fmt_tag2str(dnnl_format_tag_t v) {
     if (v == dnnl_gOIdhw2o8i16o2i) return "gOIdhw2o8i16o2i";
     if (v == dnnl_gOIw2o8i16o4i) return "gOIw2o8i16o4i";
     if (v == dnnl_gOIhw2o8i16o4i) return "gOIhw2o8i16o4i";
+    if (v == dnnl_BA8b4a) return "BA8b4a";
+    if (v == dnnl_BA4b4a) return "BA4b4a";
+    if (v == dnnl_Ab4a) return "Ab4a";
+    if (v == dnnl_Ab8a) return "Ab8a";
     assert(!"unknown fmt_tag");
     return "unknown fmt_tag";
 }
diff --git a/src/common/memory_desc_wrapper.cpp b/src/common/memory_desc_wrapper.cpp
index 06097aaa729..ccf4d26d997 100644
--- a/src/common/memory_desc_wrapper.cpp
+++ b/src/common/memory_desc_wrapper.cpp
@@ -186,6 +186,12 @@ status_t memory_desc_wrapper::compute_blocking(
         C(Abc4a, {0, 1, 2}, {4}, {0});
         C(aBc4b, {0, 1, 2}, {4}, {1});
 
+        C(Ab4a, {0, 1}, {4}, {0});
+        C(Ab8a, {0, 1}, {8}, {0});
+
+        C(BA4b4a, {1, 0}, {4, 4}, {1, 0});
+        C(BA8b4a, {1, 0}, {8, 4}, {1, 0});
+
         C(BA16a16b, {1, 0}, {16, 16}, {0, 1});
         C(BA16a32b, {1, 0}, {16, 32}, {0, 1});
         C(BA16a48b, {1, 0}, {16, 48}, {0, 1});
diff --git a/src/cpu/aarch64/acl_reorder.hpp b/src/cpu/aarch64/acl_reorder.hpp
index 78cb0e4c4d3..8593773e69d 100644
--- a/src/cpu/aarch64/acl_reorder.hpp
+++ b/src/cpu/aarch64/acl_reorder.hpp
@@ -87,11 +87,12 @@ struct acl_reorder_fwd_t : public primitive_t {
 
             using namespace acl_utils;
 
-            bool ok = src_md->data_type
-                            == dst_md->data_type // ACL reorder only supports matching src/dst data types
-                    && utils::one_of(src_md->data_type,
-                            data_type::f32) // Only supports f32 for now
+            // ACL reorder support f32->f32 and f32->bf16
+            bool ok = src_md->data_type == data_type::f32
+                    && utils::one_of(
+                            dst_md->data_type, data_type::f32, data_type::bf16)
                     && attr->has_default_values();
+
             if (!ok) return status::unimplemented;
 
             int mask = -1;
@@ -109,95 +110,69 @@ struct acl_reorder_fwd_t : public primitive_t {
                 return status::unimplemented;
             }
 
+            // In case we have two or four dimensions we can't have the first
+            // two dimensions as 1. This is valid for f32->f32 and f32->bf16.
+            if (dst_md->dims[0] == 1 || dst_md->dims[1] == 1) {
+                return status::unimplemented;
+            }
+
             auto src_tag = memory_desc_matches_one_of_tag(
-                    *src_md, format_tag::ba, format_tag::cdba);
-            ACL_CHECK_SUPPORT(utils::one_of(format_tag::undef, src_tag),
-                    "Only ba and cdba source formats supported");
+                    *src_md, format_tag::ab, format_tag::ba, format_tag::cdba);
+            ACL_CHECK_SUPPORT(format_tag::undef == src_tag,
+                    "Only ab, ba or cdba source formats supported");
+
+            auto dst_tag = memory_desc_matches_one_of_tag(*dst_md,
+                    format_tag::BA8b4a, format_tag::BA4b4a, format_tag::Ab4a,
+                    format_tag::Ab8a);
+            ACL_CHECK_SUPPORT(format_tag::undef == dst_tag,
+                    "Only Ab4a, Ab8a, BA8b4a and BA4b4a destination formats "
+                    "supported");
+
+            if (dst_tag == format_tag::BA4b4a || dst_tag == format_tag::Acdb4a
+                    || dst_tag == format_tag::Ab4a) {
+                _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo4;
+            } else if (dst_tag == format_tag::BA8b4a
+                    || dst_tag == format_tag::Acdb8a
+                    || dst_tag == format_tag::Ab8a) {
+                _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo8;
+            } else {
+                return status::unimplemented;
+            }
 
             arm_compute::TensorShape acl_tensor_shape_in;
             arm_compute::TensorShape acl_tensor_shape_out;
-            const memory_desc_wrapper src_d(*src_md);
-            const int ndims = src_d.ndims();
-            // Need even amount of dims in dim 0 for ACL kernel (eg mulitple of 8 rows when blocking by 8)
-            int dim_0_rounded_up;
 
             // Switch for 2 or 4 dim tensors
-            switch (ndims) {
-                // Currently for Ab4a and Ab8a
-                // No format_tag for these, have to deduce from stride
+            switch (src_md->ndims) {
                 case 2: {
-                    if (dst_md->dims[0] == 1 || dst_md->dims[1] == 1) {
-                        return status::unimplemented;
-                    }
-                    int dst_dim_1 = dst_md->dims[1];
-                    int dst_dim_0_stride
-                            = dst_md->format_desc.blocking.strides[0];
-                    int dst_dim_1_stride
-                            = dst_md->format_desc.blocking.strides[1];
-                    // Interleave of 4 or 8 that stride for dim 1
-                    if (dst_dim_1_stride != 4 && dst_dim_1_stride != 8) {
-                        return status::unimplemented;
-                    }
-                    // Check to ensure it's a blocking transpose
-                    if (dst_dim_1 * dst_dim_1_stride != dst_dim_0_stride) {
-                        return status::unimplemented;
-                    }
-                    if (dst_dim_1_stride == 4) {
-                        // Set Dest WeightFormat
-                        _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo4;
-                        dim_0_rounded_up = utils::rnd_up(src_md->dims[0], 4);
-                        // Blocking for Ab8a only supported with SVE length 256
-                    } else if (dst_dim_1_stride == 8 && mayiuse(sve_256)) {
-                        // Set Dest WeightFormat
-                        _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo8;
-                        dim_0_rounded_up = utils::rnd_up(src_md->dims[0], 8);
+                    if (src_tag == format_tag::ab
+                            && dst_md->data_type == data_type::bf16) { // bf16
+                        acl_tensor_shape_in = arm_compute::TensorShape(
+                                src_md->dims[0], src_md->dims[1]);
+                        acl_tensor_shape_out = arm_compute::TensorShape(
+                                dst_md->padded_dims[0], dst_md->padded_dims[1]);
+                    } else if (src_tag == format_tag::ba
+                            && dst_md->data_type == data_type::f32) { // f32
+                        acl_tensor_shape_in = arm_compute::TensorShape(
+                                src_md->dims[1], src_md->dims[0]);
+                        acl_tensor_shape_out = arm_compute::TensorShape(
+                                dst_md->padded_dims[1], dst_md->padded_dims[0]);
                     } else {
                         return status::unimplemented;
                     }
-                    acl_tensor_shape_in = arm_compute::TensorShape(
-                            src_md->dims[1], src_md->dims[0]);
-                    acl_tensor_shape_out = arm_compute::TensorShape(
-                            src_md->dims[1], dim_0_rounded_up);
-
-                    break;
-                }
-                // Currently supports Acdb4a and Acdb8a
+                } break;
                 case 4: {
-
-                    auto dst_tag = memory_desc_matches_one_of_tag(
-                            *dst_md, format_tag::Acdb4a, format_tag::Acdb8a);
-                    ACL_CHECK_SUPPORT(utils::one_of(format_tag::undef, dst_tag),
-                            "Only Acdb4a and Acdb8a dst format supported for "
-                            "4d tensors");
-
-                    if (dst_tag == format_tag::Acdb4a) {
-                        // Set Dest WeightFormat
-                        _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo4;
-                        dim_0_rounded_up = utils::rnd_up(src_md->dims[0], 4);
-                        // Blocking for Acdb8a only supported with SVE length 256
-                    } else if (dst_tag == format_tag::Acdb8a
-                            && mayiuse(sve_256)) {
-                        // Set Dest WeightFormat
-                        _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo8;
-                        dim_0_rounded_up = utils::rnd_up(src_md->dims[0], 8);
-                    } else {
-                        return status::unimplemented;
-                    }
                     // Currently only supporting AxBx1x1 cases
                     if (dst_md->dims[2] != 1 || dst_md->dims[3] != 1) {
                         return status::unimplemented;
                     }
 
-                    if (dst_md->dims[0] == 1 || dst_md->dims[1] == 1) {
-                        return status::unimplemented;
-                    }
-
                     acl_tensor_shape_in = arm_compute::TensorShape(
                             src_md->dims[3], src_md->dims[2], src_md->dims[1],
                             src_md->dims[0]);
                     acl_tensor_shape_out = arm_compute::TensorShape(
-                            src_md->dims[3], src_md->dims[2], src_md->dims[1],
-                            dim_0_rounded_up);
+                            dst_md->padded_dims[3], dst_md->padded_dims[2],
+                            dst_md->padded_dims[1], dst_md->padded_dims[0]);
                     break;
                 }
                 default: return status::unimplemented;
@@ -210,13 +185,15 @@ struct acl_reorder_fwd_t : public primitive_t {
             _pd->app_.src_wf = arm_compute::WeightFormat::OHWI;
 
             // Create ACL tensor infos
-            const data_type_t data_type = src_d.data_type();
-            const arm_compute::DataType acl_data_t
-                    = acl_utils::get_acl_data_t(data_type);
+            const arm_compute::DataType src_acl_data_t
+                    = acl_utils::get_acl_data_t(src_md->data_type);
             _pd->app_.src_info = arm_compute::TensorInfo(
-                    acl_tensor_shape_in, 1, acl_data_t, acl_layout);
+                    acl_tensor_shape_in, 1, src_acl_data_t, acl_layout);
+
+            const arm_compute::DataType dst_acl_data_t
+                    = acl_utils::get_acl_data_t(dst_md->data_type);
             _pd->app_.dst_info = arm_compute::TensorInfo(
-                    acl_tensor_shape_out, 1, acl_data_t, acl_layout);
+                    acl_tensor_shape_out, 1, dst_acl_data_t, acl_layout);
 
             ACL_CHECK_VALID(arm_compute::NEReorderLayer::validate(
                     &_pd->app_.src_info, &_pd->app_.dst_info, _pd->app_.src_wf,
diff --git a/src/cpu/platform.cpp b/src/cpu/platform.cpp
index 3319eb1837d..cedfff68a3b 100644
--- a/src/cpu/platform.cpp
+++ b/src/cpu/platform.cpp
@@ -117,6 +117,8 @@ bool has_data_type_support(data_type_t data_type) {
 #if defined(USE_CBLAS) && defined(BLAS_HAS_SBGEMM) && defined(__MMA__)
             return true;
 #endif
+#elif DNNL_AARCH64_USE_ACL
+            return arm_compute::CPUInfo::get().has_bf16();
 #else
             return false;
 #endif
@@ -151,6 +153,8 @@ bool has_training_support(data_type_t data_type) {
 #if defined(USE_CBLAS) && defined(BLAS_HAS_SBGEMM) && defined(__MMA__)
             return true;
 #endif
+#elif DNNL_AARCH64_USE_ACL
+            return arm_compute::CPUInfo::get().has_bf16();
 #else
             return false;
 #endif
diff --git a/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp b/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp
index d4e21d316eb..213f44723f7 100644
--- a/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp
+++ b/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp
@@ -35,6 +35,7 @@ const impl_list_map_t &regular_f32_bf16_impl_list_map() {
             DNNL_NON_X64_ONLY(REG_SR_BIDIR(f32, any, bf16, nChw16c))
             DNNL_NON_X64_ONLY(REG_SR_BIDIR(f32, any, bf16, nCdhw16c))
 
+            DNNL_AARCH64_ACL_ONLY(CPU_REORDER_INSTANCE(aarch64::acl_reorder_fwd_t))
             DNNL_AARCH64_ONLY(CPU_REORDER_INSTANCE(aarch64::jit_uni_reorder_t))
 
             DNNL_NON_X64_ONLY(REG_SR(f32, oihw, bf16, OIhw8i16o2i, fmt_order::keep))
