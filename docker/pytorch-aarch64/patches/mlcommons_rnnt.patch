# *******************************************************************************
# Copyright 2021 Arm Limited and affiliates.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# *******************************************************************************
#
# This patch file includes commit 077f823ece09e37d9d40540d8acd504bf138e880
# from the MLCommons inference repository, and further additions to make
# the shell scripts suitable for building and running on AArch64 systems
# without Conda installed.
#
# *******************************************************************************
diff --git a/speech_recognition/rnnt/README.md b/speech_recognition/rnnt/README.md
index 27fbabd..2794bed 100644
--- a/speech_recognition/rnnt/README.md
+++ b/speech_recognition/rnnt/README.md
@@ -4,18 +4,12 @@ character transcription, without an external language model.
 
 # 2. Directions
 
-Open `run.sh`. Set the stage variable to "-1". Set "work_dir" to a
-path backed by a disk with at least 30 GB of space. Most space is used
-by loadgen logs, not the data or model. You need conda and a C/C++
-compiler on your PATH. I used conda 4.8.2. This script is responsible
-for downloading dependencies, data, and the model.
-
-Run `./run.sh` from this directory. Note that stage 3 runs all of the
-scenarios for the reference implementation, which will take a long
-time, so you may want to exist before then.
-
-As you complete individual stages, you can set the variable "stage" to
-a higher number for restarting from a later stage.
+To download the dataset and model, run `download_dataset_model.sh`.
+To run the model, use `run.sh`; this shell script runs the SingleStream
+scenario by default if no others are specified. Use `run.sh --help` to
+view the full list of available flags and a usage example. Note that
+the RNNT directory will need to be a path backed by a disk with at least 30
+GB of space. Most space is used by loadgen logs, not the data or model.
 
 # 3. Dataset/Environment
 ### Publication/Attribution
@@ -113,4 +107,4 @@ The differences are as follows:
 ### Quality metric
 7.452253714852645% Word Error Rate (WER) across all words in the output text of
 all samples less than 15 seconds in length in the dev-clean set, using a greedy
-decoder and a fully FP32 model.
\ No newline at end of file
+decoder and a fully FP32 model.
diff --git a/speech_recognition/rnnt/download_dataset_model.sh b/speech_recognition/rnnt/download_dataset_model.sh
new file mode 100755
index 0000000..8d4ac05
--- /dev/null
+++ b/speech_recognition/rnnt/download_dataset_model.sh
@@ -0,0 +1,46 @@
+#!/bin/bash
+# *******************************************************************************
+# Copyright 2021 Arm Limited and affiliates.
+# SPDX-License-Identifier: Apache-2.0
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# *******************************************************************************
+set -euo pipefail
+
+base="$(dirname "${BASH_SOURCE[0]}")"
+work_dir=$base/temp_work
+local_data_dir=$work_dir/local_data
+librispeech_download_dir=$local_data_dir/LibriSpeech
+
+mkdir -p $librispeech_download_dir
+
+# if venv not active, activate
+if [[ $(python -c "import sys; print(sys.prefix)") != "/home/ubuntu/python3-venv" ]]; then
+    source /home/ubuntu/python3-venv/bin/activate
+fi
+
+# stage 0: download model. Check checksum to skip?
+wget https://zenodo.org/record/3662521/files/DistributedDataParallel_1576581068.9962234-epoch-100.pt?download=1 -O $work_dir/rnnt.pt
+
+# stage 1: download data. This will have a non-zero exit code if the
+# checksum is incorrect.
+python pytorch/utils/download_librispeech.py \
+     pytorch/utils/librispeech-inference.csv \
+     $librispeech_download_dir \
+     -e $local_data_dir
+
+# stage 2: perform necessary conversions on data
+python pytorch/utils/convert_librispeech.py \
+  --input_dir $librispeech_download_dir/dev-clean \
+  --dest_dir $local_data_dir/dev-clean-wav \
+  --output_json $local_data_dir/dev-clean-wav.json
diff --git a/speech_recognition/rnnt/pytorch/rnn.py b/speech_recognition/rnnt/pytorch/rnn.py
index 9bbea9c..39e2121 100644
--- a/speech_recognition/rnnt/pytorch/rnn.py
+++ b/speech_recognition/rnnt/pytorch/rnn.py
@@ -96,12 +96,14 @@ class StackTime(torch.nn.Module):
 
     def forward(self, x, x_lens):
         # T, B, U
-        seq = [x]
-        for i in range(1, self.factor):
-            # This doesn't seem to make much sense...
-            tmp = torch.zeros_like(x)
-            tmp[:-i, :, :] = x[i:, :, :]
-            seq.append(tmp)
+        r = torch.transpose(x, 0, 1)
+        s = r.shape
+        zeros = torch.zeros(
+            s[0], (-s[1]) % self.factor, s[2], dtype=r.dtype, device=r.device)
+        r = torch.cat([r, zeros], 1)
+        s = r.shape
+        rs = [s[0], s[1] // self.factor, s[2] * self.factor]
+        r = torch.reshape(r, rs)
+        rt = torch.transpose(r, 0, 1)
         x_lens = torch.ceil(x_lens.float() / self.factor).int()
-        # Gross, this is horrible. What a waste of memory...
-        return torch.cat(seq, dim=2)[::self.factor, :, :], x_lens
+        return rt, x_lens
diff --git a/speech_recognition/rnnt/run.sh b/speech_recognition/rnnt/run.sh
index 7538df9..d65a87c 100755
--- a/speech_recognition/rnnt/run.sh
+++ b/speech_recognition/rnnt/run.sh
@@ -1,90 +1,108 @@
-#/bin/bash
-
+#!/bin/bash
+# *******************************************************************************
+# Copyright 2021 Arm Limited and affiliates.
+# SPDX-License-Identifier: Apache-2.0
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# *******************************************************************************
 set -euo pipefail
 
-work_dir=/export/b07/ws15dgalvez/mlperf-rnnt-librispeech
-local_data_dir=$work_dir/local_data
-librispeech_download_dir=$local_data_dir/LibriSpeech
-stage=3
-
-mkdir -p $work_dir $local_data_dir $librispeech_download_dir
-
-install_dir=third_party/install
-mkdir -p $install_dir
-install_dir=$(readlink -f $install_dir)
-
-set +u
-source "$($CONDA_EXE info --base)/etc/profile.d/conda.sh"
-set -u
-
-# stage -1: install dependencies
-if [[ $stage -le -1 ]]; then
-    conda env create --force -v --file environment.yml
-
-    set +u
-    source "$(conda info --base)/etc/profile.d/conda.sh"
-    conda activate mlperf-rnnt
-    set -u
-
-    # We need to convert .flac files to .wav files via sox. Not all sox installs have flac support, so we install from source.
-    wget https://ftp.osuosl.org/pub/xiph/releases/flac/flac-1.3.2.tar.xz -O third_party/flac-1.3.2.tar.xz
-    (cd third_party; tar xf flac-1.3.2.tar.xz; cd flac-1.3.2; ./configure --prefix=$install_dir && make && make install)
-
-    wget https://sourceforge.net/projects/sox/files/sox/14.4.2/sox-14.4.2.tar.gz -O third_party/sox-14.4.2.tar.gz
-    (cd third_party; tar zxf sox-14.4.2.tar.gz; cd sox-14.4.2; LDFLAGS="-L${install_dir}/lib" CFLAGS="-I${install_dir}/include" ./configure --prefix=$install_dir --with-flac && make && make install)
-
-    (cd $(git rev-parse --show-toplevel)/loadgen; python setup.py install)
+################################################################################
+function print_usage_and_exit {
+  echo "Usage: run.sh [OPTIONS]"
+  echo ""
+  echo "Options:"
+  echo "  -h, --help                   Display this message"
+  echo "  --accuracy                   Run accuracy tests instead of performance tests"
+  echo "  --all                        Run all tests: SingleStream, Offline, Server"
+  echo "  --single-stream              Run SingleStream scenario (default if no other specified)"
+  echo "  --offline                    Run Offline scenario"
+  echo "  --server                     Run Server scenario"
+  echo ""
+  echo "Example:"
+  echo "  run.sh --offline --server --accuracy"
+  exit $1
+}
+################################################################################
+
+# default args
+all_flag=false
+acc_flag=''
+scenarios=''
+
+while [ $# -gt 0 ]
+do
+  case $1 in
+    --single-stream )
+      scenarios="$scenarios SingleStream"
+      shift
+      ;;
+    --offline )
+      scenarios="$scenarios Offline"
+      shift
+      ;;
+    --server )
+      scenarios="$scenarios Server"
+      shift
+      ;;
+    --all )
+      all_flag=true
+      shift
+      ;;
+    --accuracy )
+      acc_flag='--accuracy'
+      shift
+      ;;
+    -h | --help )
+      print_usage_and_exit 0
+      ;;
+  esac
+done
+
+# set scenarios here if --all to avoid duplication
+if $all_flag; then
+  scenarios='SingleStream Offline Server'
 fi
 
-export PATH="$install_dir/bin/:$PATH"
-
-set +u
-conda activate mlperf-rnnt
-set -u
-
-# stage 0: download model. Check checksum to skip?
-if [[ $stage -le 0 ]]; then
-  wget https://zenodo.org/record/3662521/files/DistributedDataParallel_1576581068.9962234-epoch-100.pt?download=1 -O $work_dir/rnnt.pt
+# set SingleStream default if no scenario specified
+if [ -z "$scenarios" ]; then
+  scenarios="SingleStream"
 fi
 
-# stage 1: download data. This will hae a non-zero exit code if the
-# checksum is incorrect.
-if [[ $stage -le 1 ]]; then
-  python pytorch/utils/download_librispeech.py \
-         pytorch/utils/librispeech-inference.csv \
-         $librispeech_download_dir \
-         -e $local_data_dir
-fi
+base="$(dirname "${BASH_SOURCE[0]}")"
+work_dir=$base/temp_work
+local_data_dir=$work_dir/local_data
 
-if [[ $stage -le 2 ]]; then
-  python pytorch/utils/convert_librispeech.py \
-      --input_dir $librispeech_download_dir/dev-clean \
-      --dest_dir $local_data_dir/dev-clean-wav \
-      --output_json $local_data_dir/dev-clean-wav.json
+# if venv not active, activate
+if [[ $(python -c "import sys; print(sys.prefix)") != "/home/ubuntu/python3-venv" ]]; then
+    source /home/ubuntu/python3-venv/bin/activate
 fi
 
-if [[ $stage -le 3 ]]; then
-  for backend in pytorch; do
-    for accuracy in "--accuracy" ""; do
-      for scenario in SingleStream Offline Server; do
-        log_dir=${work_dir}/${scenario}_${backend}
-        if [ ! -z ${accuracy} ]; then
-          log_dir+=_accuracy
-        fi
-        log_dir+=rerun
-
-        python run.py --backend pytorch \
-               --dataset_dir $local_data_dir \
-               --manifest $local_data_dir/dev-clean-wav.json \
-               --pytorch_config_toml pytorch/configs/rnnt.toml \
-               --pytorch_checkpoint $work_dir/rnnt.pt \
-               --scenario ${scenario} \
-               --backend ${backend} \
-               --log_dir ${log_dir} \
-               ${accuracy} &
-
-      done
-    done
-  done
-  wait
-fi
+for scenario in $scenarios; do
+  log_dir=${work_dir}/${scenario}_pytorch
+  if [ ! -z ${acc_flag} ]; then
+    log_dir+=_accuracy
+  fi
+  log_dir+=rerun
+
+  python run.py --backend pytorch \
+       --dataset_dir $local_data_dir \
+       --manifest $local_data_dir/dev-clean-wav.json \
+       --pytorch_config_toml pytorch/configs/rnnt.toml \
+       --pytorch_checkpoint $work_dir/rnnt.pt \
+       --scenario ${scenario} \
+       --backend pytorch \
+       --log_dir ${log_dir} \
+       ${acc_flag} &
+done
+wait
