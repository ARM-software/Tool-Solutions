*******************************************************************************
 Copyright 2024 Arm Limited and affiliates.
 SPDX-License-Identifier: Apache-2.0

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 *******************************************************************************

diff --git a/src/cpu/aarch64/acl_convolution_utils.cpp b/src/cpu/aarch64/acl_convolution_utils.cpp
index c62ed1ce90..af42643841 100644
--- a/src/cpu/aarch64/acl_convolution_utils.cpp
+++ b/src/cpu/aarch64/acl_convolution_utils.cpp
@@ -62,8 +62,13 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,
                               everyone_is(data_type::f32, src_d.data_type(),
                                       wei_d.data_type(), dst_d.data_type()),
                               everyone_is(data_type::f16, src_d.data_type(),
-                                      wei_d.data_type(), dst_d.data_type())),
-            " src, dst and wei must be fp16 or fp32");
+                                      wei_d.data_type(), dst_d.data_type()),
+                              everyone_is(data_type::s8, src_d.data_type(),
+                                      wei_d.data_type(), dst_d.data_type()),
+                              (everyone_is(data_type::u8, src_d.data_type(),
+                                       dst_d.data_type())
+                                      && wei_d.data_type() == data_type::s8)),
+            " src, dst and wei must be s8, u8, bf16, fp16 or fp32");

     // batch size
     const int mb = src_d.dims()[0];
@@ -162,8 +167,11 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,
     const auto acl_layout = is_nhwc ? arm_compute::DataLayout::NHWC
                                     : arm_compute::DataLayout::NCHW;

+    bool is_quantized
+            = utils::one_of(src_d.data_type(), data_type::s8, data_type::u8);
     // all have the same datatype
-    auto acl_data_type = acl_utils::get_acl_data_t(src_d.data_type());
+    auto acl_data_type
+            = acl_utils::get_acl_data_t(src_d.data_type(), is_quantized);

     // clang-format off
     acp.src_tensor_info = arm_compute::TensorInfo(
@@ -177,8 +185,9 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,
             is_nhwc ? arm_compute::TensorShape(ic, kw, kh, oc) :
             arm_compute::TensorShape(kw, kh, ic, oc),
             1,
-            acl_data_type,
+            acl_utils::get_acl_data_t(wei_d.data_type(), is_quantized),
             acl_layout);
+
     if(is_depthwise) {
        // We need to set that values are not constant so that we
        // we can update them in-place in ACL
@@ -196,10 +205,17 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,
             acp.with_bias ? arm_compute::TensorShape(oc)
                           : arm_compute::TensorShape(),
             1,
-            acl_data_type,
+            is_quantized ? acl_utils::get_acl_data_t(data_type::s32) : acl_data_type,
             acl_layout);
     // clang-format on

+    if (is_quantized) {
+        arm_compute::QuantizationInfo qi {1.0, 0, true};
+        acp.src_tensor_info.set_quantization_info(qi);
+        acp.wei_tensor_info.set_quantization_info(qi);
+        acp.dst_tensor_info.set_quantization_info(qi);
+    }
+
     // ACL Winograd is not prepared for fixed format kernels
     if (acp.alg_winograd) {
         const bool is_1d = ndims == 3;
@@ -214,7 +230,7 @@ status_t acl_init_conf(acl_conv_conf_t &acp, memory_desc_t &src_md,
     // Are we allowed to cast down to bf16 or not?
     acp.fast_math
             = one_of(attr.fpmath_.mode_, fpmath_mode::bf16, fpmath_mode::any);
-    if (is_depthwise) {
+    if (is_depthwise || is_quantized) {
         // There is no support for fixed format kernels for depthwise convolution
         // in ACL so we are going to use weight format that we set up earlier
         return status::success;
diff --git a/src/cpu/aarch64/acl_gemm_convolution.cpp b/src/cpu/aarch64/acl_gemm_convolution.cpp
index a569d7e2b7..efd6c3c355 100644
--- a/src/cpu/aarch64/acl_gemm_convolution.cpp
+++ b/src/cpu/aarch64/acl_gemm_convolution.cpp
@@ -1,5 +1,5 @@
 /*******************************************************************************
-* Copyright 2020-2022 Arm Ltd. and affiliates
+* Copyright 2020-2022, 2024 Arm Ltd. and affiliates
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -44,6 +44,7 @@ using namespace data_type;
 template struct acl_gemm_convolution_fwd_t<f32>;
 template struct acl_gemm_convolution_fwd_t<f16>;
 template struct acl_gemm_convolution_fwd_t<s8, s8, s8, s32>;
+template struct acl_gemm_convolution_fwd_t<u8, s8, u8, s32>;

 } // namespace aarch64
 } // namespace cpu
diff --git a/src/cpu/aarch64/acl_gemm_convolution.hpp b/src/cpu/aarch64/acl_gemm_convolution.hpp
index efae57f0b2..adfa62f878 100644
--- a/src/cpu/aarch64/acl_gemm_convolution.hpp
+++ b/src/cpu/aarch64/acl_gemm_convolution.hpp
@@ -18,6 +18,7 @@
 #define CPU_AARCH64_ACL_GEMM_CONVOLUTION_HPP

 #include "cpu/cpu_convolution_pd.hpp"
+#include "cpu/cpu_primitive.hpp"

 #include "cpu/aarch64/acl_convolution_utils.hpp"
 #include "cpu/aarch64/acl_post_ops.hpp"
@@ -79,9 +80,8 @@ struct acl_gemm_convolution_fwd_t : public primitive_t {
                     && expect_data_types(
                             src_type, wei_type, bia_type, dst_type, undef)
                     && !has_zero_dim_memory()
-                    && attr()->has_default_values(
-                            smask_t::post_ops | smask_t::fpmath_mode, dst_type)
                     && output_scales_mask_ok() && zero_points_ok();
+
             if (!ok) return status::unimplemented;

             CHECK(acl_convolution_utils::init_conf_gemm(acp_, src_md_,
@@ -117,8 +117,8 @@ struct acl_gemm_convolution_fwd_t : public primitive_t {

         bool zero_points_ok() const {
             using namespace data_type;
-            // TODO: add support for asymmetric quantization
-            return attr()->zero_points_.has_default_values();
+            return IMPLICATION(!utils::one_of(src_type, s8, u8),
+                    attr()->zero_points_.has_default_values());
         }
     };

@@ -146,6 +146,38 @@ struct acl_gemm_convolution_fwd_t : public primitive_t {
     typedef typename prec_traits<bia_type>::type bia_data_t;

     status_t execute(const exec_ctx_t &ctx) const override {
+        auto &acl_obj = ctx.get_resource_mapper()
+                                ->get<acl_resource_t>(this)
+                                ->get_acl_obj();
+
+        bool is_quantized
+                = utils::one_of(acl_obj.dst_tensor.info()->data_type(),
+                        arm_compute::DataType::QASYMM8,
+                        arm_compute::DataType::QASYMM8_SIGNED);
+
+        if (is_quantized) {
+            DEFINE_ARG_SCALES_BUFFER(src_scale, DNNL_ARG_SRC);
+            DEFINE_ZERO_POINT_VALUE(src_zero_point, DNNL_ARG_SRC);
+            DEFINE_ARG_SCALES_BUFFER(wei_scale, DNNL_ARG_WEIGHTS);
+            DEFINE_ZERO_POINT_VALUE(wei_zero_point, DNNL_ARG_WEIGHTS);
+            DEFINE_ARG_SCALES_BUFFER(dst_scale, DNNL_ARG_DST);
+            DEFINE_ZERO_POINT_VALUE(dst_zero_point, DNNL_ARG_DST);
+
+            // s8s8s8 uses D = Sx*Sy*(XY + X*zy + Y*zx + zx*zy) and u8s8u8 uses D = Sx*Sy*(XW - X*zw - W*zx + zx*zw)
+            if (acl_obj.dst_tensor.info()->data_type() == arm_compute::DataType::QASYMM8)
+            {
+                acl_obj.src_tensor.info()->set_quantization_info(arm_compute::QuantizationInfo(*src_scale, -src_zero_point, true));
+                acl_obj.wei_tensor.info()->set_quantization_info(arm_compute::QuantizationInfo(*wei_scale, -wei_zero_point, true));
+            } else
+            {
+                acl_obj.src_tensor.info()->set_quantization_info(arm_compute::QuantizationInfo(*src_scale, src_zero_point, true));
+                acl_obj.wei_tensor.info()->set_quantization_info(arm_compute::QuantizationInfo(*wei_scale, wei_zero_point, true));
+            }
+
+            // for efficiency reasons, OneDNN saves the inverse of the destination
+            acl_obj.dst_tensor.info()->set_quantization_info(arm_compute::QuantizationInfo(1.0/(*dst_scale), dst_zero_point, true));
+        }
+
         return execute_forward(ctx);
     }

diff --git a/src/cpu/cpu_convolution_list.cpp b/src/cpu/cpu_convolution_list.cpp
index dcdddedfac..ae6e321901 100644
--- a/src/cpu/cpu_convolution_list.cpp
+++ b/src/cpu/cpu_convolution_list.cpp
@@ -613,6 +613,7 @@ const std::map<pk_dt_impl_key_t, std::vector<impl_list_item_t>> &impl_list_map()
             nullptr,
         }},
         {{forward, u8, s8, u8}, {
+            CPU_INSTANCE_AARCH64_ACL(acl_gemm_convolution_fwd_t<u8, s8, u8, s32>)
             CPU_INSTANCE_AVX512(brdgmm_dw_convolution_fwd_t)
             CPU_INSTANCE_X64(ip_convolution_fwd_t)
             CPU_INSTANCE_AMX(brgemm_1x1_convolution_fwd_t<avx512_core_amx>)
--
2.25.1

