 *******************************************************************************
 Copyright 2020 Arm Limited and affiliates.
 SPDX-License-Identifier: Apache-2.0

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 *******************************************************************************

diff --git a/vision/classification_and_detection/python/main.py b/vision/classification_and_detection/python/main.py
index cd6825f..282448b 100755
--- a/vision/classification_and_detection/python/main.py
+++ b/vision/classification_and_detection/python/main.py
@@ -202,6 +202,7 @@ def get_args():
     parser.add_argument("--count", type=int, help="dataset items to use")
     parser.add_argument("--max-latency", type=float, help="mlperf max latency in pct tile")
     parser.add_argument("--samples-per-query", type=int, help="mlperf multi-stream sample per query")
+    parser.add_argument("--initialize-dataset", type=bool, default=False, help="initialize the dataset")
     args = parser.parse_args()
 
     # don't use defaults in argparser. Instead we default to a dict, override that with a profile
@@ -428,6 +429,8 @@ def main():
                         pre_process=pre_proc,
                         use_cache=args.cache,
                         count=count, **kwargs)
+    if args.initialize_dataset:
+        return
     # load model to backend
     model = backend.load(args.model, inputs=args.inputs, outputs=args.outputs)
     final_results = {
diff --git a/vision/classification_and_detection/run_cnn.py b/vision/classification_and_detection/run_cnn.py
new file mode 100755
index 0000000..5f12f1e
--- /dev/null
+++ b/vision/classification_and_detection/run_cnn.py
@@ -0,0 +1,143 @@
+#!/usr/bin/env python3
+"""
+ Copyright 2020 Arm Limited and affiliates.
+ SPDX-License-Identifier: Apache-2.0
+
+ Licensed under the Apache License, Version 2.0 (the "License");
+ you may not use this file except in compliance with the License.
+ You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+"""
+
+
+import os
+import sh
+import sys
+import argparse
+import shutil
+from itertools import chain
+if sys.version_info[0] < 3:
+    from itertools import izip_longest as zip_longest
+else:
+    from itertools import zip_longest
+
+
+def num(value):
+    try:
+        return int(value)
+    except ValueError:
+        return float(value)
+
+
+def get_args():
+    """Parse commandline."""
+    parser = argparse.ArgumentParser()
+    parser.add_argument("--backend", default="tf",
+            choices=["tf", "pytorch", "onnxruntime"],
+            help="name of the mlperf backend, ie. tf")
+    parser.add_argument("--model", default="resnet50",
+            choices=["resnet50", "mobilenet", "ssd-mobilenet", "ssd-resnet34"],
+            help="name of the mlperf model, ie. resnet50")
+    parser.add_argument("--device", default="cpu",
+            choices=["cpu", "gpu"],
+            help="name of the mlperf device, ie. cpu")
+    parser.add_argument("--scenario", default="SingleStream",
+            choices=["SingleStream", "MultiStream", "Server", "Offline"],
+            help="mlperf benchmark scenario, ie. SingleStream")
+    parser.add_argument("--processes", default=1, type=int, help="processes")
+    parser.add_argument("--threads", default=os.cpu_count(), type=int, help="threads")
+
+    return  parser.parse_args()
+
+
+def get_online_cpus():
+    online_cpus = []
+    from sh import lscpu
+    for line in lscpu().split('\n'):
+        if "On-line CPU(s) list:" in line:
+            num_list = [item.strip() for item in (line.split(':'))[1].split(',')]
+            for item in num_list:
+                if '-' in item:
+                    a, b = item.split('-')
+                    online_cpus.append(range(int(a), int(b)+1))
+                else:
+                    online_cpus.append([int(item)])
+            break
+
+    return [item for item in chain(*zip_longest(*online_cpus)) if item is not None]
+
+
+
+def main():
+    # parse arguments in the command line
+    args = get_args()
+    run_exe = './run_local.sh'
+    run_params = [args.backend, args.model, args.device, '--scenario', args.scenario]
+    assert(args.processes * args.threads <= os.cpu_count())
+
+    # recommend disabling smt if possible
+    if os.path.exists('/sys/devices/system/cpu/smt/active'):
+        with open('/sys/devices/system/cpu/smt/active', 'r') as f:
+            if f.read().strip() == '1':
+                sys.stderr.write('Error: please disable smt using \"echo off > /sys/devices/system/cpu/smt/control\"\n')
+                sys.exit(1)
+
+    # get a list of online cpus
+    online_cpu_list = get_online_cpus()
+
+    # set OneDNN environment variables
+    os.environ['KMP_AFFINITY'] = 'granularity=fine,verbose,compact,1,0'
+    os.environ['KMP_BLOCKTIME'] = '0'
+    os.environ['KMP_WARNINGS'] = '0'
+    os.environ['KMP_SETTINGS'] = '0'
+
+    # prepare the dataset
+    sh.Command(run_exe)(run_params + ['--initialize-dataset', 'True'])
+
+    # run multiple multithreaded processes with affinity settings
+    os.environ['OMP_NUM_THREADS'] = str(args.threads)
+    os.environ['MLPERF_NUM_INTRA_THREADS'] = str(args.threads)
+    output_parent_dir = 'output/{}-{}/{}'.format(args.backend, args.device, args.model)
+
+    aff_list = [None] * args.processes
+    output_dirs = [None] * args.processes
+    for proc_index in range(args.processes):
+        aff_list[proc_index] = ','.join([str(item) for item in
+                online_cpu_list[proc_index * args.threads : (proc_index + 1) * args.threads]])
+        output_dirs[proc_index] = '{}/p{}'.format(output_parent_dir, proc_index)
+        if os.path.exists(output_dirs[proc_index]):
+            shutil.rmtree(output_dirs[proc_index], ignore_errors=True)
+        os.makedirs(output_dirs[proc_index])
+
+    processes = [None] * args.processes
+    for proc_index in range(args.processes):
+        output_dir = output_dirs[proc_index]
+        processes[proc_index] = sh.taskset('-c', aff_list[proc_index],
+                run_exe, run_params + ['--threads', str(args.threads), '--output', output_dir],
+                _out='{}/mlperf_log_out.txt'.format(output_dir), _err_to_out=True, _bg=True)
+    for proc in processes:
+        proc.wait()
+
+    # proces the data
+    scores = [None] * args.processes
+    valids = [None] * args.processes
+    for proc_index in range(args.processes):
+        with open('{}/mlperf_log_summary.txt'.format(output_dirs[proc_index])) as f:
+            output = f.readlines()
+        score = num(output[6].split(':')[1].strip())
+        scores[proc_index] = score / 1e6 if args.scenario == 'SingleStream' else score
+        valids[proc_index] = output[7].split(':')[1].strip()
+
+    print(scores)
+    print(valids)
+
+
+if __name__ == "__main__":
+    main()
