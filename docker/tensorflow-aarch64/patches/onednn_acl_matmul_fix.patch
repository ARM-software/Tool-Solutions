 *******************************************************************************
 Copyright 2022 Arm Limited and affiliates.
 SPDX-License-Identifier: Apache-2.0

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 *******************************************************************************
diff --git a/src/cpu/aarch64/matmul/acl_matmul.hpp b/src/cpu/aarch64/matmul/acl_matmul.hpp
index 13d2ab07a..f77987a42 100644
--- a/src/cpu/aarch64/matmul/acl_matmul.hpp
+++ b/src/cpu/aarch64/matmul/acl_matmul.hpp
@@ -84,8 +84,8 @@ struct acl_matmul_t : public primitive_t {
                     && attr_oscale_ok() && !has_runtime_dims_or_strides();
             if (!ok) return status::unimplemented;
 
-            CHECK(acl_matmul_utils::init_conf_matmul(amp_, src_md_, weights_md_,
-                    dst_md_, bias_md_, *desc(), *attr()));
+            CHECK(acl_matmul_utils::init_conf_matmul(
+                    amp_, src_md_, weights_md_, dst_md_, *desc(), *attr()));
 
             arm_compute::ActivationLayerInfo act_info;
             CHECK(post_ops_pd.init(engine, dst_md_, attr_.post_ops_, act_info));
diff --git a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp
index 5e48c9882..679baec3a 100644
--- a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp
+++ b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp
@@ -23,60 +23,68 @@ namespace impl {
 namespace cpu {
 namespace aarch64 {
 
-using namespace alg_kind;
-using namespace cpu::matmul;
-using namespace format_tag;
-
 namespace acl_matmul_utils {
 
 status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,
-        memory_desc_t &wei_md, memory_desc_t &dst_md, memory_desc_t &bias_md,
-        const matmul_desc_t &md, const primitive_attr_t &attr) {
+        memory_desc_t &wei_md, memory_desc_t &dst_md, const matmul_desc_t &md,
+        const primitive_attr_t &attr) {
 
     const memory_desc_wrapper src_d(&src_md);
     const memory_desc_wrapper wei_d(&wei_md);
     const memory_desc_wrapper dst_d(&dst_md);
-    const memory_desc_wrapper bia_d(&bias_md);
 
-    matmul_helper_t helper(src_d, wei_d, dst_d);
+    cpu::matmul::matmul_helper_t helper(src_d, wei_d, dst_d);
     const dim_t M = helper.M();
     const dim_t N = helper.N();
     const dim_t K = helper.K();
-    const dim_t batch = helper.batch();
+    const dim_t dst_batch = helper.batch();
+    const dim_t src_batch = helper.src_batch();
+    const dim_t wei_batch = helper.wei_batch();
+
+    // ACL supports broadcast for 3D shapes, and 4D shapes
+    // for e.g when ab in abcd is 1x1
+    bool batch_ok = IMPLICATION(src_batch > 1, wei_batch == 1)
+            && IMPLICATION(wei_batch > 1, src_batch == 1);
+    ACL_CHECK_SUPPORT(src_d.ndims() == 4 && src_batch != wei_batch && !batch_ok,
+            "matmul broadcast supported only for 3D shapes and 4D shapes when "
+            "ab is 1x1");
 
     // ACL does not support bias
-    amp.with_bias = md.bias_desc.format_kind != format_kind::undef;
-    if (amp.with_bias) return status::unimplemented;
+    bool with_bias = md.bias_desc.format_kind != format_kind::undef;
+    ACL_CHECK_SUPPORT(with_bias, "ACL does not support bias for matmul");
 
+    using namespace format_tag;
     auto src_tag = memory_desc_matches_one_of_tag(
             src_md, abcd, abdc, abc, acb, ab, ba);
     auto wei_tag = memory_desc_matches_one_of_tag(
             wei_md, abcd, abdc, abc, acb, ab, ba);
-    auto dst_tag = memory_desc_matches_one_of_tag(
-            dst_md, abcd, abdc, abc, acb, ab, ba);
-    if (utils::one_of(format_tag::undef, src_tag, wei_tag, dst_tag)) {
-        return status::unimplemented;
-    }
+    auto dst_tag
+            = memory_desc_matches_one_of_tag(dst_md, abcd, abc, acb, ab, ba);
+    ACL_CHECK_SUPPORT(
+            utils::one_of(format_tag::undef, src_tag, wei_tag, dst_tag),
+            "Format tag is undefined");
+
+    // Transpose A (src) or B (wei)
     amp.is_transA = helper.transA() == 'T';
     amp.is_transB = helper.transB() == 'T';
     if (amp.is_transA)
         amp.src_acc_info = arm_compute::TensorInfo(
-                arm_compute::TensorShape(M, K, 1, batch), 1,
+                arm_compute::TensorShape(M, K, 1, src_batch), 1,
                 arm_compute::DataType::F32);
     if (amp.is_transB)
-        amp.wei_acc_info
-                = arm_compute::TensorInfo(arm_compute::TensorShape(K, N, batch),
-                        1, arm_compute::DataType::F32);
+        amp.wei_acc_info = arm_compute::TensorInfo(
+                arm_compute::TensorShape(K, N, wei_batch), 1,
+                arm_compute::DataType::F32);
 
-    amp.src_info
-            = arm_compute::TensorInfo(arm_compute::TensorShape(K, M, 1, batch),
-                    1, arm_compute::DataType::F32);
+    amp.src_info = arm_compute::TensorInfo(
+            arm_compute::TensorShape(K, M, 1, src_batch), 1,
+            arm_compute::DataType::F32);
     amp.wei_info
-            = arm_compute::TensorInfo(arm_compute::TensorShape(N, K, batch), 1,
-                    arm_compute::DataType::F32);
-    amp.dst_info
-            = arm_compute::TensorInfo(arm_compute::TensorShape(N, M, 1, batch),
+            = arm_compute::TensorInfo(arm_compute::TensorShape(N, K, wei_batch),
                     1, arm_compute::DataType::F32);
+    amp.dst_info = arm_compute::TensorInfo(
+            arm_compute::TensorShape(N, M, 1, dst_batch), 1,
+            arm_compute::DataType::F32);
 
     // Fast-math mode
     auto math_mode = get_fpmath_mode();
diff --git a/src/cpu/aarch64/matmul/acl_matmul_utils.hpp b/src/cpu/aarch64/matmul/acl_matmul_utils.hpp
index 662f9c3c5..0a5ee6a98 100644
--- a/src/cpu/aarch64/matmul/acl_matmul_utils.hpp
+++ b/src/cpu/aarch64/matmul/acl_matmul_utils.hpp
@@ -38,7 +38,6 @@ struct acl_matmul_obj_t {
 };
 
 struct acl_matmul_conf_t {
-    bool with_bias;
     bool is_transA;
     bool is_transB;
     // If this is true, the result of the matmul goes into a temporarily
@@ -56,8 +55,8 @@ struct acl_matmul_conf_t {
 namespace acl_matmul_utils {
 
 status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,
-        memory_desc_t &wei_md, memory_desc_t &dst_md, memory_desc_t &bias_md,
-        const matmul_desc_t &md, const primitive_attr_t &attr);
+        memory_desc_t &wei_md, memory_desc_t &dst_md, const matmul_desc_t &md,
+        const primitive_attr_t &attr);
 
 } // namespace acl_matmul_utils
 
diff --git a/src/cpu/matmul/matmul_utils.hpp b/src/cpu/matmul/matmul_utils.hpp
index bb24ba7ba..df21e3e50 100644
--- a/src/cpu/matmul/matmul_utils.hpp
+++ b/src/cpu/matmul/matmul_utils.hpp
@@ -1,5 +1,6 @@
 /*******************************************************************************
 * Copyright 2020 Intel Corporation
+* Copyright 2022 Arm Ltd. and affiliates
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -38,6 +39,13 @@ struct matmul_helper_t {
     dim_t batch() const {
         return utils::array_product(dst_md_.dims(), ndims() - 2);
     };
+    dim_t src_batch() const {
+        return utils::array_product(src_md_.dims(), ndims() - 2);
+    };
+    dim_t wei_batch() const {
+        return utils::array_product(weights_md_.dims(), ndims() - 2);
+    };
+
     dim_t M() const { return dst_md_.dims()[ndims() - 2]; }
     dim_t N() const { return dst_md_.dims()[ndims() - 1]; }
     dim_t K() const { return src_md_.dims()[ndims() - 1]; }
diff --git a/tests/benchdnn/inputs/matmul/test_matmul_all b/tests/benchdnn/inputs/matmul/test_matmul_all
index c118b59f4..a7dd99a58 100644
--- a/tests/benchdnn/inputs/matmul/test_matmul_all
+++ b/tests/benchdnn/inputs/matmul/test_matmul_all
@@ -74,3 +74,14 @@
 
 # matmul with strides
 --batch=harness_matmul_strides
+
+# 4d
+
+--reset
+--cfg=f32
+--stag=abcd,abdc --wtag=abcd,abdc --dtag=abcd,abdc
+--bia_dt=undef,f32
+
+--attr-oscale=common:2.25
+--attr-post-ops=,relu,sum,sum+relu+add:f32,binary_mul:f32+sum
+--batch=shapes_4d
\ No newline at end of file
